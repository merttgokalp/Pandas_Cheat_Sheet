{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/lofo/lofo_importance.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c045d0ca632e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as py\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "import pandas_profiling\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "my_scorer = make_scorer(mean_absolute_percentage_error, greater_is_better=False)\n",
    "\n",
    "def generate_dataset(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def train_linear_model(X,y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle = False, stratify = None,random_state=42)\n",
    "\n",
    "    regr = LinearRegression()\n",
    "\n",
    "    regr = regr.fit(X_train,y_train)\n",
    "\n",
    "    predictions = regr.predict(X_test)\n",
    "\n",
    "    actual = y_test\n",
    "\n",
    "    # calculate RMSE\n",
    "    rmse = math.sqrt(mean_squared_error(actual, predictions))\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "    pct = mean_absolute_percentage_error(actual,predictions)\n",
    "    print('MAPE : %.3f' % pct +'%' )\n",
    "    \n",
    "    cv_scores = np.abs(cross_val_score(regr, X, y,scoring=my_scorer,cv=25))\n",
    "   \n",
    "    print('CV Score :', cv_scores )\n",
    "    \n",
    "    print('CV Score Mean:', np.mean(cv_scores))\n",
    "    \n",
    "    rmse_percentage = (rmse/y.mean())*100\n",
    "    print('RMSE Percentage : %.3f' % rmse_percentage +'%' )\n",
    "\n",
    "    rmse_std = rmse/y.std()\n",
    "    print('RMSE/STD : %.3f' % rmse_std +'%' )\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x = np.arange(0,len(y_train)),\n",
    "                                     y = y_train['var1(t)'],\n",
    "                                     mode='lines+markers', name='Train'))\n",
    "    fig.add_trace(go.Scatter(x = np.arange(len(X_train),len(X_train)+len(actual)),\n",
    "                                     y = actual['var1(t)'],\n",
    "                                     mode='lines+markers', name='Actual'))\n",
    "    fig.add_trace(go.Scatter(x = np.arange(len(X_train),len(X_train)+len(actual)),\n",
    "                                     y = predictions[:,0],\n",
    "                                     mode='lines+markers', name='Prediction'))\n",
    "    fig.update_layout(title=\"Mean Abs. Pct Error \" + '%'+str(round(pct,2)),\n",
    "                    )\n",
    "    fig.show()\n",
    "    \n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('DailyDelhiClimateTrain.csv')\n",
    "train.index = pd.to_datetime(train.date)\n",
    "train = train.drop(columns=['date'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('DailyDelhiClimateTest.csv')\n",
    "test.index = pd.to_datetime(test.date)\n",
    "test = test.drop(columns=['date'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Supervised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed = generate_dataset(train, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=4, shuffle=False, random_state=0)\n",
    "\n",
    "ds = Dataset(df=reframed, target=\"var1(t)\", features=[col for col in reframed.columns if col != 'var1(t)'])\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "lofo_imp = LOFOImportance(ds, cv=cv, scoring=\"neg_mean_squared_error\",model = model)\n",
    "\n",
    "# get the mean and standard deviation of the importances in pandas format\n",
    "importance_df = lofo_imp.get_importance()\n",
    "\n",
    "# plot the means and standard deviations of the importances\n",
    "plot_importance(importance_df, figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = importance_df.feature.head(10).values\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(reframed['var1(t)'])\n",
    "\n",
    "X = pd.DataFrame(reframed[features])\n",
    "\n",
    "train_linear_model(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled = train.copy()\n",
    "#resampled = resampled.resample('W', on=\"date\").mean()  Date = Index, no need to define \"on\" parameter\n",
    "resampled = resampled.resample('W').mean()\n",
    "display(resampled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
